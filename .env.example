# PromptSentinel Configuration
#
# ⚠️ SECURITY WARNING: Never commit real API keys or sensitive credentials!
# See docs/SECURE_SECRETS.md for secure secret management options:
#   - HashiCorp Vault (recommended for teams)
#   - Python Keyring (local development)
#   - Encrypted .env files (dotenv-vault)
#   - Cloud secret managers (AWS, Azure, GCP)
#
# For examples, see: examples/secret_management/

# API Configuration
# API_HOST: Network interface to bind to
#   - 0.0.0.0 = Listen on all interfaces (allows external connections)
#   - 127.0.0.1 or localhost = Local connections only (more secure for development)
API_HOST=0.0.0.0

# API_PORT: TCP port for the service
#   - 8080 = Common development port (no special privileges needed)
#   - 80 = Standard HTTP (requires root/admin on some systems)
#   - 443 = Standard HTTPS (requires SSL cert configuration)
API_PORT=8080

# API_ENV: Environment mode affecting security and performance
#   - development = Verbose errors, relaxed security, auto-reload
#   - staging = Production-like with some debug features
#   - production = Optimized performance, strict security, minimal logging
API_ENV=development

# DEBUG: Enable/disable debug mode
#   - true = Show stack traces, enable auto-reload, verbose logging
#   - false = Hide sensitive errors, better performance
#   ⚠️ ALWAYS set to false in production for security
DEBUG=true

# LLM Provider Configuration
# Order of providers to try (comma-separated)
LLM_PROVIDER_ORDER=anthropic,openai,gemini

# Primary: Anthropic
ANTHROPIC_API_KEY=your-anthropic-api-key
ANTHROPIC_MODEL=claude-3-haiku-20240307
ANTHROPIC_MAX_TOKENS=1000
ANTHROPIC_TEMPERATURE=0.3

# Secondary: OpenAI
OPENAI_API_KEY=your-openai-api-key
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.3

# Fallback: Google Gemini
GEMINI_API_KEY=your-gemini-api-key
GEMINI_MODEL=gemini-1.5-flash  # gemini-pro is deprecated, use gemini-1.5-flash or gemini-2.0-flash
GEMINI_MAX_TOKENS=1000
GEMINI_TEMPERATURE=0.3

# Redis Cache Configuration (optional - system works without it)
# Redis provides optional caching to reduce LLM API calls by 30-40%
REDIS_ENABLED=false
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=changeme-in-production
REDIS_TTL=3600

# Cache TTLs for different types (seconds)
CACHE_TTL_LLM=3600         # LLM classification results (1 hour)
CACHE_TTL_DETECTION=600    # Full detection results (10 minutes)
CACHE_TTL_PATTERN=1800     # Pattern matching results (30 minutes)
CACHE_TTL_HEALTH=60        # Health check results (1 minute)

# Authentication Configuration
# Authentication mode: none (sidecar), optional (mixed), required (Public)
AUTH_MODE=optional
AUTH_ENFORCE_HTTPS=false
# Comma-separated CIDR networks to bypass auth (e.g., 10.0.0.0/8,172.16.0.0/12)
AUTH_BYPASS_NETWORKS=
# Comma-separated header:value pairs to bypass auth (e.g., X-Internal:true,X-Service:gateway)
AUTH_BYPASS_HEADERS=
AUTH_ALLOW_LOCALHOST=true
# Rate limits for unauthenticated requests
AUTH_UNAUTHENTICATED_RPM=10
AUTH_UNAUTHENTICATED_TPM=1000
# API key configuration
API_KEY_PREFIX=psk_
API_KEY_LENGTH=32

# CORS Configuration (important for production)
# Configure Cross-Origin Resource Sharing for browser-based clients
CORS_ENABLED=true
# Comma-separated list of allowed origins (use specific URLs in production, avoid *)
CORS_ALLOW_ORIGINS=http://localhost:3000,http://localhost:8080
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=GET,POST,PUT,DELETE,OPTIONS
CORS_ALLOW_HEADERS=Content-Type,Authorization,X-API-Key,X-Client-ID
CORS_MAX_AGE=3600  # Preflight cache time in seconds

# Security Headers Configuration
# Protect against common web vulnerabilities
SECURITY_HEADERS_ENABLED=true
SECURITY_HSTS_ENABLED=true    # HTTP Strict Transport Security (HTTPS only)
SECURITY_CSP_ENABLED=true      # Content Security Policy
# SECURITY_CSP_REPORT_URI=https://your-domain.com/csp-report  # Optional CSP reporting

# Detection Configuration
DETECTION_MODE=strict  # strict, moderate, permissive
DETECTION_TIMEOUT=10.0
HEURISTIC_ENABLED=true
LLM_CLASSIFICATION_ENABLED=true
CONFIDENCE_THRESHOLD=0.7

# Budget Configuration
# Set spending limits to control LLM API costs
BUDGET_HOURLY_LIMIT=10.0        # Maximum spend per hour in USD
BUDGET_DAILY_LIMIT=100.0         # Maximum spend per day in USD
BUDGET_MONTHLY_LIMIT=1000.0      # Maximum spend per month in USD
BUDGET_BLOCK_ON_EXCEEDED=true    # Block requests when budget exceeded
BUDGET_PREFER_CACHE=true         # Prefer cached results to save costs

# Rate Limiting Configuration
# Control request throughput to prevent abuse and manage load
RATE_LIMIT_REQUESTS_PER_MINUTE=60           # Global requests per minute
RATE_LIMIT_TOKENS_PER_MINUTE=10000          # Global tokens per minute
RATE_LIMIT_CLIENT_REQUESTS_PER_MINUTE=20    # Per-client requests per minute

# Security Configuration
MAX_PROMPT_LENGTH=50000
RATE_LIMIT_PER_IP=1000
RATE_LIMIT_PER_KEY=10000
ALLOWED_CHARSETS=utf-8,ascii

# Monitoring & Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
ENABLE_METRICS=true
ENABLE_TRACING=false
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318

# Security Scanning Configuration
# Snyk authentication token for vulnerability scanning
# Get your token from: https://app.snyk.io/account
SNYK_TOKEN=your-snyk-auth-token

# Snyk Organization ID (required for SBOM generation)
# Get your org ID from: https://app.snyk.io/account
SNYK_ORG_ID=your-snyk-org-id

# ============================================================================
# OPTIONAL: HashiCorp Vault Integration
# ============================================================================
# If using HashiCorp Vault for secret management (recommended):
# See docs/SECURE_SECRETS.md for setup instructions
#
# VAULT_ADDR=http://127.0.0.1:8200       # Vault server address
# VAULT_TOKEN=<your-app-token>           # Application token (limited permissions)
# VAULT_PATH=secret/promptsentinel       # Path to secrets in Vault
# SECRET_METHOD=vault                    # Enable Vault integration
#
# For local development with Vault:
#   1. Install Vault: brew install hashicorp/tap/vault
#   2. Start Vault: vault server -dev
#   3. Store secrets: vault kv put secret/promptsentinel/api_keys anthropic=<key>
#   4. Set VAULT_TOKEN and SECRET_METHOD=vault
# ============================================================================

# Corpus Management
CORPUS_AUTO_UPDATE=false
CORPUS_UPDATE_INTERVAL=86400
CORPUS_SOURCES=https://example.com/corpus.jsonl

# PII Detection Configuration
PII_DETECTION_ENABLED=true
# PII Redaction modes:
#   mask: Replace PII with masked values (e.g., ***-**-1234)
#   remove: Replace with [TYPE_REMOVED] placeholders
#   hash: Replace with hashed values for consistency
#   reject: Block the entire request if PII is detected
#   pass-silent: ⚠️ DANGEROUS - Pass PII through without modification (NOT RECOMMENDED)
#   pass-alert: ⚠️ WARNING - Pass PII through but log and alert (USE WITH CAUTION)
PII_REDACTION_MODE=mask
PII_TYPES_TO_DETECT=all  # all or comma-separated: credit_card,ssn,email,phone
PII_LOG_DETECTED=false  # Set to true with pass-alert to log PII detection warnings
PII_CONFIDENCE_THRESHOLD=0.7

# ============================================================================
# PRODUCTION CONFIGURATION EXAMPLE
# ============================================================================
# For production deployments, consider these recommended settings:
#
# API_HOST=0.0.0.0                        # Or specific IP for security
# API_PORT=80                             # Standard port (or 443 with SSL)
# API_ENV=production                      # Production mode
# DEBUG=false                             # ⚠️ CRITICAL: Must be false
#
# DETECTION_MODE=strict                   # Maximum security
# LLM_CLASSIFICATION_ENABLED=true         # Enable for best accuracy
# PII_REDACTION_MODE=reject               # Zero tolerance for PII
# PII_LOG_DETECTED=false                  # Never log actual PII
#
# RATE_LIMIT_PER_IP=100                   # Stricter rate limits
# MAX_PROMPT_LENGTH=10000                 # Smaller limit to prevent abuse
#
# LOG_LEVEL=WARNING                       # Less verbose logging
# ENABLE_METRICS=true                     # Enable monitoring
# ENABLE_TRACING=true                     # Enable distributed tracing
# ============================================================================